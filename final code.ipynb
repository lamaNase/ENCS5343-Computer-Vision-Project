{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7400778,"sourceType":"datasetVersion","datasetId":4303344},{"sourceId":7470318,"sourceType":"datasetVersion","datasetId":4348768},{"sourceId":7500708,"sourceType":"datasetVersion","datasetId":4367762}],"dockerImageVersionId":30636,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n\n# Path to the training and testing image folders\ntrain_folder = \"/kaggle/input/project/train/train\"\ntest_folder = \"/kaggle/input/project/test/test\"\n\n# Path to the training and testing labels CSV files\ntrain_labels_file = \"/kaggle/input/project/csvTrainLabel 13440x1.csv\"\ntest_labels_file = \"/kaggle/input/project/csvTestLabel 3360x1.csv\"\n\n# Load and preprocess training data\ndef load_and_preprocess_data(folder_path, labels_file):\n    labels = pd.read_csv(labels_file, header=None, names=['label']).to_numpy()\n\n    images = []\n    for i in range(1, len(labels) + 1):\n        img_path = os.path.join(folder_path, f\"id_{i}_label_{labels[i-1, 0]}.png\")\n        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(32, 32), color_mode='grayscale')\n        img_array = tf.keras.preprocessing.image.img_to_array(img)\n        images.append(img_array)\n\n    images = np.array(images)\n    images = images / 255.0\n\n    labels_one_hot = to_categorical(labels - 1, num_classes=28)\n\n    return images, labels_one_hot\n\ntrain_images, train_labels = load_and_preprocess_data(train_folder, train_labels_file)\ntest_images, test_labels = load_and_preprocess_data(test_folder, test_labels_file)\nprint(\"Finish\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\n\n# Function to build the CNN model\ndef build_cnn_model(input_shape=(32, 32, 1), num_classes=28):\n    model = models.Sequential()\n\n    # First Convolutional Layer\n    model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same', strides=(1, 1)))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.BatchNormalization())\n\n    # Second Convolutional Layer\n    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=(1, 1)))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.BatchNormalization())\n\n    # Third Convolutional Layer\n    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same', strides=(1, 1)))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.BatchNormalization())\n\n    # Flatten the output\n    model.add(layers.Flatten())\n\n    # Fully Connected Layers\n    model.add(layers.Dense(4096, activation='relu'))\n    model.add(layers.Dropout(0.6))\n    model.add(layers.Dense(1024, activation='relu'))\n    model.add(layers.Dropout(0.6))\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.Dropout(0.6))\n\n    # Output Layer\n    model.add(layers.Dense(num_classes, activation='softmax'))\n\n    return model\n\n# Define Hyperparameters\nlearning_rate = 0.0001\nbatch_size = 16\nepochs = 20\n\n# Create an instance of the Adam optimizer with the specified learning rate\ncustom_optimizer = Adam(learning_rate=learning_rate)\n\n# Build the CNN model\ncnn_model = build_cnn_model()\n\n# Compile the model\ncnn_model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model and get the history object\nhistory = cnn_model.fit(\n    train_images, \n    train_labels, \n    epochs=epochs, \n    batch_size=batch_size, \n    validation_data=(test_images, test_labels),  # Validation data for each epoch\n)\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = cnn_model.evaluate(test_images, test_labels)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Plot the training history\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Testing Accuracy')  # Plot validation accuracy against epochs\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Testing Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation --- part 1\n# This cell is to fine tune the zoom range on the testing accuercy and loss\n\n# Define a range of zoom levels to test\nzoom_ranges = [0.1, 0.2, 0.3, 0.4, 0.5]\n\n# Lists to store testing accuracies and losses for each zoom range\ntesting_accuracies = []\ntesting_losses = []\n\nfor zoom_range in zoom_ranges:\n    # Create an instance of ImageDataGenerator with the current zoom range\n    datagen = ImageDataGenerator(\n        zoom_range=zoom_range,\n        fill_mode='nearest'\n    )\n\n    # Apply data augmentation to the entire training dataset\n    augmented_train_data = datagen.flow(train_images, train_labels, batch_size=32)\n\n    # Combine original training data with augmented data\n    combined_train_data = np.concatenate([train_images, augmented_train_data[0][0]], axis=0)\n    combined_train_labels = np.concatenate([train_labels, augmented_train_data[0][1]], axis=0)\n\n    # Create an instance of the Adam optimizer with the specified learning rate\n    custom_optimizer = Adam(learning_rate=learning_rate)\n\n    # Build the CNN model\n    new_model = build_cnn_model()\n\n    # Compile the model\n    new_model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model using combined data\n    new_model.fit(\n        combined_train_data,\n        combined_train_labels,\n        batch_size=16,\n        epochs=epochs,\n        validation_data=(test_images, test_labels),\n        verbose=0\n    )\n\n    # Evaluate the model on the test dataset\n    test_loss, test_accuracy = new_model.evaluate(test_images, test_labels)\n    testing_accuracies.append(test_accuracy)\n    testing_losses.append(test_loss)\n\n# Plot the testing accuracies against zoom ranges\nplt.figure(figsize=(12, 4))\n\n# Plot Testing Accuracy\nplt.subplot(1, 2, 1)\nplt.plot(zoom_ranges, testing_accuracies, marker='o')\nplt.xlabel('Zoom Range')\nplt.ylabel('Testing Accuracy')\nplt.title('Effect of Zoom Range on Testing Accuracy')\n\n# Plot Testing Loss\nplt.subplot(1, 2, 2)\nplt.plot(zoom_ranges, testing_losses, marker='o', color='orange')\nplt.xlabel('Zoom Range')\nplt.ylabel('Testing Loss')\nplt.title('Effect of Zoom Range on Testing Loss')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation --- part 2\n# This cell is to fine tune the width shift range on the testing accuercy and loss\n\n# Define a range of zoom levels to test\nwidth_shift_ranges = [0.1, 0.2, 0.3, 0.4, 0.5]\n\n# Lists to store testing accuracies and losses for each zoom range\ntesting_accuracies = []\ntesting_losses = []\n\nfor width_range in width_shift_ranges:\n    # Create an instance of ImageDataGenerator with the current zoom range\n    datagen = ImageDataGenerator(\n        zoom_range=0.5,\n        fill_mode='nearest',\n        width_shift_range=width_range\n    )\n\n    # Apply data augmentation to the entire training dataset\n    augmented_train_data = datagen.flow(train_images, train_labels, batch_size=32)\n\n    # Combine original training data with augmented data\n    combined_train_data = np.concatenate([train_images, augmented_train_data[0][0]], axis=0)\n    combined_train_labels = np.concatenate([train_labels, augmented_train_data[0][1]], axis=0)\n\n    # Create an instance of the Adam optimizer with the specified learning rate\n    custom_optimizer = Adam(learning_rate=learning_rate)\n\n    # Build the CNN model\n    new_model = build_cnn_model()\n\n    # Compile the model\n    new_model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model using combined data\n    new_model.fit(\n        combined_train_data,\n        combined_train_labels,\n        batch_size=16,\n        epochs=epochs,\n        validation_data=(test_images, test_labels),\n        verbose=0\n    )\n\n    # Evaluate the model on the test dataset\n    test_loss, test_accuracy = new_model.evaluate(test_images, test_labels)\n    testing_accuracies.append(test_accuracy)\n    testing_losses.append(test_loss)\n\n# Plot the testing accuracies against zoom ranges\nplt.figure(figsize=(12, 4))\n\n# Plot Testing Accuracy\nplt.subplot(1, 2, 1)\nplt.plot(width_shift_ranges, testing_accuracies, marker='o')\nplt.xlabel('Width Shift Range')\nplt.ylabel('Testing Accuracy')\nplt.title('Effect of Width Shift Range on Testing Accuracy')\n\n# Plot Testing Loss\nplt.subplot(1, 2, 2)\nplt.plot(width_shift_ranges, testing_losses, marker='o', color='orange')\nplt.xlabel('Width Shift Range')\nplt.ylabel('Testing Loss')\nplt.title('Effect of Width Shift Range on Testing Loss')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation --- part 3\n# This cell is to fine tune the height shift range on the testing accuercy and loss\n\n# Define a range of zoom levels to test\nheight_shift_ranges = [0.1, 0.2, 0.3, 0.4, 0.5]\n\n# Lists to store testing accuracies and losses for each zoom range\ntesting_accuracies = []\ntesting_losses = []\n\nfor height_range in height_shift_ranges:\n    # Create an instance of ImageDataGenerator with the current zoom range\n    datagen = ImageDataGenerator(\n        zoom_range=0.5,\n        fill_mode='nearest',\n        width_shift_range=0.1,\n        height_shift_range=height_range\n    )\n\n    # Apply data augmentation to the entire training dataset\n    augmented_train_data = datagen.flow(train_images, train_labels, batch_size=32)\n\n    # Combine original training data with augmented data\n    combined_train_data = np.concatenate([train_images, augmented_train_data[0][0]], axis=0)\n    combined_train_labels = np.concatenate([train_labels, augmented_train_data[0][1]], axis=0)\n\n    # Create an instance of the Adam optimizer with the specified learning rate\n    custom_optimizer = Adam(learning_rate=learning_rate)\n\n    # Build the CNN model\n    new_model = build_cnn_model()\n\n    # Compile the model\n    new_model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model using combined data\n    new_model.fit(\n        combined_train_data,\n        combined_train_labels,\n        batch_size=16,\n        epochs=epochs,\n        validation_data=(test_images, test_labels),\n        verbose=0\n    )\n\n    # Evaluate the model on the test dataset\n    test_loss, test_accuracy = new_model.evaluate(test_images, test_labels)\n    testing_accuracies.append(test_accuracy)\n    testing_losses.append(test_loss)\n\n# Plot the testing accuracies against zoom ranges\nplt.figure(figsize=(12, 4))\n\n# Plot Testing Accuracy\nplt.subplot(1, 2, 1)\nplt.plot(height_shift_ranges, testing_accuracies, marker='o')\nplt.xlabel('height Shift Range')\nplt.ylabel('Testing Accuracy')\nplt.title('Effect of height Shift Range on Testing Accuracy')\n\n# Plot Testing Loss\nplt.subplot(1, 2, 2)\nplt.plot(height_shift_ranges, testing_losses, marker='o', color='orange')\nplt.xlabel('height Shift Range')\nplt.ylabel('Testing Loss')\nplt.title('Effect of height Shift Range on Testing Loss')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation --- part 4\n# This cell is to fine tune the rotation range on the testing accuercy and loss\n\n# Define a range of rotation angles to test\nrotation_ranges = [10, 15, 20, 25, 30]\n\n# Lists to store testing accuracies and losses for each rotation range\ntesting_accuracies = []\ntesting_losses = []\n\nfor rotation_range in rotation_ranges:\n    # Create an instance of ImageDataGenerator with the current rotation range\n    datagen = ImageDataGenerator(\n        width_shift_range=0.1,\n        height_shift_range=0.2,\n        zoom_range=0.5,\n        fill_mode='nearest',\n        rotation_range=rotation_range\n    )\n\n    # Apply data augmentation to the entire training dataset\n    augmented_train_data = datagen.flow(train_images, train_labels, batch_size=32)\n\n    # Combine original training data with augmented data\n    combined_train_data = np.concatenate([train_images, augmented_train_data[0][0]], axis=0)\n    combined_train_labels = np.concatenate([train_labels, augmented_train_data[0][1]], axis=0)\n\n    # Create an instance of the Adam optimizer with the specified learning rate\n    custom_optimizer = Adam(learning_rate=learning_rate)\n\n    # Build the CNN model\n    new_model = build_cnn_model()\n\n    # Compile the model\n    new_model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Train the model using combined data\n    new_model.fit(\n        combined_train_data,\n        combined_train_labels,\n        batch_size=16,\n        epochs=epochs,\n        validation_data=(test_images, test_labels),\n        verbose=0\n    )\n\n    # Evaluate the model on the test dataset\n    test_loss, test_accuracy = new_model.evaluate(test_images, test_labels)\n    testing_accuracies.append(test_accuracy)\n    testing_losses.append(test_loss)\n\n# Plot the testing accuracies against rotation ranges\nplt.figure(figsize=(12, 4))\n\n# Plot Testing Accuracy\nplt.subplot(1, 2, 1)\nplt.plot(rotation_ranges, testing_accuracies, marker='o')\nplt.xlabel('Rotation Range')\nplt.ylabel('Testing Accuracy')\nplt.title('Effect of Rotation Range on Testing Accuracy')\n\n# Plot Testing Loss\nplt.subplot(1, 2, 2)\nplt.plot(rotation_ranges, testing_losses, marker='o', color='orange')\nplt.xlabel('Rotation Range')\nplt.ylabel('Testing Loss')\nplt.title('Effect of Rotation Range on Testing Loss')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation ----part 5\n# This cell is to use the data augmentation with the model specified before\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n# Create an instance of ImageDataGenerator for data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range = 20,\n    width_shift_range = 0.1,\n    height_shift_range=0.2,\n    zoom_range = 0.5,\n    fill_mode = 'nearest'\n)\n\n# Apply data augmentation to the entire training dataset\naugmented_train_data = datagen.flow(train_images, train_labels, batch_size=32)\n\n# Combine original training data with augmented data\ncombined_train_data = np.concatenate([train_images, augmented_train_data[0][0]], axis=0)\ncombined_train_labels = np.concatenate([train_labels, augmented_train_data[0][1]], axis=0)\n\n# Create an instance of the Adam optimizer with the specified learning rate\ncustom_optimizer = Adam(learning_rate=learning_rate)\n\n# Build the CNN model\nnew_model = build_cnn_model()\n\n# Compile the model\nnew_model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Now, train the model using combined data\naugmented_history = new_model.fit(\n    combined_train_data,  # Use combined training data\n    combined_train_labels,  # Use combined training labels\n    batch_size=16,\n    epochs=epochs,\n    validation_data=(test_images, test_labels),\n)\n\ntest_loss, test_accuracy = new_model.evaluate(test_images, test_labels)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Plot the training history (loss and accuracy)\nplt.figure(figsize=(12, 4))\n\n# Plot Training and Validation Loss\nplt.subplot(1, 2, 1)\nplt.plot(augmented_history.history['loss'], label='Training Loss')\nplt.plot(augmented_history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot Training and Validation Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(augmented_history.history['accuracy'], label='Training Accuracy')\nplt.plot(augmented_history.history['val_accuracy'], label='Testing Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Testing Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This cell is to resize images so that they can be used in AlexNet model\nimport cv2\n\n# Define the desired output size\noutput_size = (227, 227)\n\n# Function to resize images\ndef resize_images(images):\n    resized_images = []\n    for image in images:\n        # Convert single-channel image to 3 channels\n        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n        # Resize the image to the desired output size\n        resized_image = cv2.resize(image, output_size)\n        # Append the resized image to the list\n        resized_images.append(resized_image)\n    return np.array(resized_images)\n\n# Resize the images\nresized_combined_train_data = resize_images(combined_train_data)\nresized_test_images = resize_images(test_images)\n\n# Convert data to TensorFlow tensors and move to GPU\nresized_combined_train_data = tf.convert_to_tensor(resized_combined_train_data, dtype=tf.float32)\nresized_test_images = tf.convert_to_tensor(resized_test_images, dtype=tf.float32)\ncombined_train_labels = tf.convert_to_tensor(combined_train_labels, dtype=tf.float32)\ntest_labels = tf.convert_to_tensor(test_labels, dtype=tf.float32)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This cell is used to define and train the AlexNet model\n# Define the AlexNet model\ndef create_alexnet(input_shape=(227, 227, 3), num_classes=28):\n    model = Sequential()\n\n    # Layer 1\n    model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n\n    # Layer 2\n    model.add(Conv2D(256, (5, 5), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n\n    # Layer 3\n    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n\n    # Layer 4\n    model.add(Conv2D(384, (3, 3), padding='same', activation='relu'))\n\n    # Layer 5\n    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n\n    # Flatten\n    model.add(Flatten())\n\n    # Layer 6\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n\n    # Layer 7\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n\n    # Output layer\n    model.add(Dense(num_classes, activation='softmax'))\n\n    return model\n\n# Create an instance of the Adam optimizer with the specified learning rate\ncustom_optimizer = Adam(learning_rate=learning_rate)\n\n# Create the AlexNet model\nalexnet_model = create_alexnet()\n\n# Compile the model\nalexnet_model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Now, train the model using combined data\nalexNet_history = alexnet_model.fit(\n    resized_combined_train_data,  # Use combined training data\n    combined_train_labels,  # Use combined training labels\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_data=(resized_test_images, test_labels),\n)\n\ntest_loss, test_accuracy = alexnet_model.evaluate(resized_test_images, test_labels)\n# print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Plot the training history (loss and accuracy)\nplt.figure(figsize=(12, 4))\n\n# Plot Training and Validation Loss\nplt.subplot(1, 2, 1)\nplt.plot(alexNet_history.history['loss'], label='Training Loss')\nplt.plot(alexNet_history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot Training and Validation Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(alexNet_history.history['accuracy'], label='Training Accuracy')\nplt.plot(alexNet_history.history['val_accuracy'], label='Testing Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Testing Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\n\n# Convert grayscale images to RGB\ncombined_train_data_new = np.repeat(combined_train_data, 3, axis=-1)\ntest_images_new = np.repeat(test_images, 3, axis=-1)\n\n# Choose a pre-trained model (VGG16 in this example)\nweights_path = \"/kaggle/input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nbase_model = VGG16(weights=weights_path, include_top=False, input_shape=(32, 32, 3))\n\n# Add a new classification layer for 28 classes\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.6))\nmodel.add(layers.Dense(28, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=learning_rate),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(\n    combined_train_data_new,  # Use combined training data\n    combined_train_labels,  # Use combined training labels\n    #steps_per_epoch=len(combined_train_data) // 16,\n    epochs=epochs,\n    batch_size=batch_size,\n    validation_data=(test_images_new, test_labels),\n    #validation_steps=len(test_images) // 16\n)\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(test_images_new, test_labels)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Plot the training history (loss and accuracy)\nplt.figure(figsize=(12, 4))\n\n# Plot Training and Validation Loss\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot Training and Validation Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Testing Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Testing Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}